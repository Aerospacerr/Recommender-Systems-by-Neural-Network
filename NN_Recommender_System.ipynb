{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN Recommender System",
      "provenance": [],
      "authorship_tag": "ABX9TyPj826/PrCVulaCgUcaDsDX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rFFN8KYtYxD3"
      },
      "outputs": [],
      "source": [
        "# Here we start by importing libraries for getting the data\n",
        "# Actually, I used data by uploading Google Colab from my laptop, \n",
        "# because of my laptop's lack of ram \n",
        "# Therefore, in order to be consistent and provide integrity in the code when you run,\n",
        "# I searched and find this small downloading code to download Movielens 1M dataset. \n",
        "# \n",
        "# \n",
        "\n",
        "# Here are the download code's imports\n",
        "import io\n",
        "import os\n",
        "import math\n",
        "import copy\n",
        "import pickle\n",
        "import zipfile\n",
        "from textwrap import wrap\n",
        "from pathlib import Path\n",
        "from itertools import zip_longest\n",
        "from collections import defaultdict\n",
        "from urllib.error import URLError\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data download code starts here\n",
        "def try_download(url, download_path):\n",
        "    archive_name = url.split('/')[-1]\n",
        "    folder_name, _ = os.path.splitext(archive_name)\n",
        "    \n",
        "    try:\n",
        "        r = urlopen(url)\n",
        "    except URLError as e:\n",
        "        print('Cannot download the data. Error: %s' % s)\n",
        "        return \n",
        "\n",
        "    assert r.status == 200\n",
        "    data = r.read()\n",
        "\n",
        "    with zipfile.ZipFile(io.BytesIO(data)) as arch:\n",
        "        arch.extractall(download_path)\n",
        "        \n",
        "    print('The archive is extracted into folder: %s' % download_path)\n",
        "\n",
        "# It also includes reading the data\n",
        "def read_data(path):\n",
        "    files = {}\n",
        "    for filename in path.glob('*'):\n",
        "        if filename.suffix == '.csv':\n",
        "            files[filename.stem] = pd.read_csv(filename)\n",
        "        elif filename.suffix == '.dat':\n",
        "            if filename.stem == 'ratings':\n",
        "                columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
        "            else:\n",
        "                columns = ['movieId', 'title', 'genres']\n",
        "            data = pd.read_csv(filename, sep='::', names=columns, engine='python')\n",
        "            files[filename.stem] = data\n",
        "    return files['ratings'], files['movies']"
      ],
      "metadata": {
        "id": "LPkcAMcDY0jZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1M Movielens dataset URL\n",
        "archive_url = f'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
        "download_path = Path.home() / 'data' / 'movielens'\n",
        "\n",
        "# Download dataset\n",
        "try_download(archive_url, download_path)\n",
        "\n",
        "# Pick one of the available folders and we are done\n",
        "ratings, movies = read_data(download_path /'ml-1m')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qzVBZb6Y4wc",
        "outputId": "3ea80950-d8cf-4f28-a30e-bbfa9b70f133"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The archive is extracted into folder: /root/data/movielens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's quickly check what we have in the dataset\n",
        "ratings.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ESRhTBj7aaqH",
        "outputId": "e8953dfd-5227-435e-aafb-203f9df0d51a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-21fa146a-eed9-411e-9e29-6452e78ff9a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>598359</th>\n",
              "      <td>3641</td>\n",
              "      <td>2745</td>\n",
              "      <td>5</td>\n",
              "      <td>966486091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845545</th>\n",
              "      <td>5082</td>\n",
              "      <td>1673</td>\n",
              "      <td>2</td>\n",
              "      <td>962407875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194591</th>\n",
              "      <td>1201</td>\n",
              "      <td>314</td>\n",
              "      <td>4</td>\n",
              "      <td>975208105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209756</th>\n",
              "      <td>1281</td>\n",
              "      <td>1171</td>\n",
              "      <td>4</td>\n",
              "      <td>974793020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>658116</th>\n",
              "      <td>3965</td>\n",
              "      <td>3773</td>\n",
              "      <td>4</td>\n",
              "      <td>965671672</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21fa146a-eed9-411e-9e29-6452e78ff9a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21fa146a-eed9-411e-9e29-6452e78ff9a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21fa146a-eed9-411e-9e29-6452e78ff9a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        userId  movieId  rating  timestamp\n",
              "598359    3641     2745       5  966486091\n",
              "845545    5082     1673       2  962407875\n",
              "194591    1201      314       4  975208105\n",
              "209756    1281     1171       4  974793020\n",
              "658116    3965     3773       4  965671672"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "u_V2yv-Daxrw",
        "outputId": "85e80a15-c9ff-41a3-8f55-befcbeee0575"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-86313f56-64a7-492f-815e-65e70e9083ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>827</td>\n",
              "      <td>Convent, The (Convento, O) (1995)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>108</td>\n",
              "      <td>Catwalk (1995)</td>\n",
              "      <td>Documentary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>638</td>\n",
              "      <td>Jack and Sarah (1995)</td>\n",
              "      <td>Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>3611</td>\n",
              "      <td>Saludos Amigos (1943)</td>\n",
              "      <td>Animation|Children's|Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3370</th>\n",
              "      <td>3439</td>\n",
              "      <td>Teenage Mutant Ninja Turtles II: The Secret of...</td>\n",
              "      <td>Action|Children's|Fantasy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86313f56-64a7-492f-815e-65e70e9083ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86313f56-64a7-492f-815e-65e70e9083ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86313f56-64a7-492f-815e-65e70e9083ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      movieId  ...                       genres\n",
              "816       827  ...                        Drama\n",
              "106       108  ...                  Documentary\n",
              "633       638  ...                      Romance\n",
              "3542     3611  ...  Animation|Children's|Comedy\n",
              "3370     3439  ...    Action|Children's|Fantasy\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('There are {} rows of data from {} users'.format(len(ratings), len(ratings.userId.unique())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsJXku8Ua4o5",
        "outputId": "ea302c39-fbb0-4965-e4d8-328d099759bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1000209 rows of data from 6040 users\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's do some preprocessing for out data\n",
        "# Prepare it as df and encode users and movies as integer indices\n",
        "# Here we used sklearn's LabelEncoder for this process\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def create_df(df):\n",
        "\n",
        "    # Encoding users and movies as integers\n",
        "    user_enc = LabelEncoder()\n",
        "    df['user'] = user_enc.fit_transform(df['userId'].values)\n",
        "    \n",
        "    item_enc = LabelEncoder()\n",
        "    df['movie'] = item_enc.fit_transform(df['movieId'].values)\n",
        "\n",
        "    # Number of unique users and movies\n",
        "    n_users = df['user'].nunique()\n",
        "    n_movies = df['movie'].nunique()\n",
        "\n",
        "    df['rating'] = df['rating'].values.astype(np.float32)\n",
        "\n",
        "    # Min and Max ratings from the database\n",
        "    # We will use these for normalization\n",
        "    min_rating = min(df['rating'])\n",
        "    max_rating = max(df['rating'])\n",
        "\n",
        "    return n_users, n_movies, min_rating, max_rating, df\n",
        "\n"
      ],
      "metadata": {
        "id": "KLcsqUW3bCQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create our df by calling create_df function & create X,y for split\n",
        "n_users, n_movies, min_rating, max_rating, df=create_df(ratings)\n",
        "\n",
        "X = df[['user', 'movie']].values\n",
        "y = df['rating'].values # our target\n",
        "\n",
        "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
        "#y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "\n",
        "# Split by %90-%10 for train and test as we have 1M row data. \n",
        "# Test will have 100k row data.\n",
        "# We could do %95-%5 but i prefer that way. As 50k row would be enough for test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, random_state=10)\n",
        "\n",
        "# We didn't normalize our target(y) for first try, we will do it later\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "ZE98ahtjbxOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Embeddings: {n_users} users, {n_movies} movies')\n",
        "print(f'Dataset(user&movie ids) shape: {df.shape}')\n",
        "print(f'Target(ratings) shape: {y.shape}')\n",
        "\n",
        "print(f'We will use user and movie as features and rating as the target of our embedding based model.')"
      ],
      "metadata": {
        "id": "D18YONdZeB5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will start our collaborative filtering model\n",
        "# Importing tensorflow and keras\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Reshape, Dot\n",
        "from keras.regularizers import l2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make users and movies into separate arrays in the training and test data for Keras input\n",
        "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
        "X_test_array = [X_test[:, 0], X_test[:, 1]]\n",
        "\n",
        "# EmbeddingLayer as a calling class\n",
        "class EmbeddingLayer:\n",
        "    def __init__(self, n_items, n_factors):\n",
        "        self.n_items = n_items\n",
        "        self.n_factors = n_factors\n",
        "    \n",
        "    def __call__(self, Embedded):\n",
        "        Embedded = layers.Embedding(self.n_items, \n",
        "                             self.n_factors, \n",
        "                             embeddings_initializer='he_normal',\n",
        "                             embeddings_regularizer=l2(1e-6))(Embedded)\n",
        "        Embedded = Reshape((self.n_factors,))(Embedded)\n",
        "        return Embedded\n",
        "\n",
        "\n",
        "def DL_Recommender(n_users, n_movies, embedding_size=50):\n",
        "    #Creating an embedding layer having embedding vectors of user and item ids.\n",
        "    user = Input(shape=(1,))\n",
        "    u = EmbeddingLayer(n_users, embedding_size)(user)\n",
        "        \n",
        "    movie = Input(shape=(1,))\n",
        "    m = EmbeddingLayer(n_movies, embedding_size)(movie)\n",
        "    \n",
        "    # Dot product for interactions between users and items\n",
        "    interaction = Dot(axes=1)([u, m])\n",
        "\n",
        "    # We used Adam for optimizer as learning_rate=0.001\n",
        "    rec_model = Model(inputs=[user, movie], outputs=interaction)\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "\n",
        "    # Computing loss as mean squared error\n",
        "    rec_model.compile(loss='mean_squared_error', optimizer=opt)\n",
        "\n",
        "    return rec_model #recommender model "
      ],
      "metadata": {
        "id": "4iCkGI-3eYY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = rec_model(n_users, n_movies)\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "fwICO7l5gyab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model1.fit(x=X_train_array, \n",
        "                      y=y_train, \n",
        "                      batch_size=1000, \n",
        "                      epochs=10, \n",
        "                      verbose=1, \n",
        "                      validation_data=(X_test_array, y_test))"
      ],
      "metadata": {
        "id": "uiU0GB8Eg9dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history1.history1[\"loss\"])\n",
        "plt.plot(history1.history1[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J6htg0l9hIww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4HfvlDxqhL84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VnScgFlKhMd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "enZKwGpqhNDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we add neural network to our model with a dropout and concatenatation\n",
        "# Actually I tried with more dense layers and dropouts but it didn't further improve our score\n",
        "from keras.layers import Concatenate, Dense, Dropout\n",
        "\n",
        "def NNmodel(n_users, n_movies, embedding_size=50):\n",
        "    user = Input(shape=(1,))\n",
        "    u = EmbeddingLayer(n_users, embedding_size)(user)\n",
        "    \n",
        "    movie = Input(shape=(1,))\n",
        "    m = EmbeddingLayer(n_movies, embedding_size)(movie)\n",
        "    \n",
        "    # Concat on the embedding layers and dropout layer\n",
        "    interaction = Concatenate()([u, m])\n",
        "    interaction = Dropout(0.05)(interaction)\n",
        "\n",
        "    # Dense layer with relu and sigmoid activation functions for interaction    \n",
        "    interaction = Dense(1, kernel_initializer='he_normal')(interaction)\n",
        "    interaction = Activation('relu')(interaction)\n",
        "    interaction = Dropout(0.5)(interaction)\n",
        "    \n",
        "    interaction = Dense(0.1, kernel_initializer='he_normal')(interaction)\n",
        "    interaction = Activation('sigmoid')(interaction)\n",
        "\n",
        "    # Again used Adam with lr=0.001\n",
        "    NNmodel = Model(inputs=[user, movie], outputs=interaction)\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    NNmodel.compile(loss='mean_squared_error', optimizer=opt)\n",
        "\n",
        "    return NNmodel"
      ],
      "metadata": {
        "id": "4opbi99DhNW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = NNmodel(n_users, n_movies)\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "yqZeuXeSjtKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(x=X_train_array, \n",
        "                      y=y_train, \n",
        "                      batch_size=1000, \n",
        "                      epochs=10, \n",
        "                      verbose=1, \n",
        "                      validation_data=(X_test_array, y_test))"
      ],
      "metadata": {
        "id": "P-gBj3ytjcgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history2.history2[\"loss\"])\n",
        "plt.plot(history2.history2[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yv91s48vj4ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now final trick\n",
        "# We will try to normalize our target and let's see what will our NNmodel do\n",
        "\n",
        "# Normalize the target between 0 and 1. Makes it easy to train.\n",
        "y2 = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
        "\n",
        "# Again split data\n",
        "X_train, X_test, y2_train, y2_test = train_test_split(X, y2, train_size=0.9, random_state=10)\n",
        "\n",
        "X_train.shape, X_test.shape, y2_train.shape, y2_test.shape\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Sa4Dxycxj53B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = NNmodel(n_users, n_movies)\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "Qopx0pBSkU76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history3 = model3.fit(x=X_train_array, \n",
        "                      y=y2_train, \n",
        "                      batch_size=1000, \n",
        "                      epochs=10, \n",
        "                      verbose=1, \n",
        "                      validation_data=(X_test_array, y2_test))"
      ],
      "metadata": {
        "id": "7iH18TUvkXwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history3.history3[\"loss\"])\n",
        "plt.plot(history3.history3[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5Op8uOntkk8P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}